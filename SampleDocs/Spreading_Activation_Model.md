# 活性化拡散モデル（Spreading Activation Model）

## 1. 活性化拡散モデルの起源
活性化拡散モデルは、元々1970年代に認知心理学の分野で Allan M. Collins と Elizabeth F. Loftus によって提唱された概念です。人間の脳がどのように意味記憶（Semantic Memory）を構造化し、情報を取り出しているかを説明するための理論として誕生しました。
脳内の記憶は、概念を「ノード」、それらの概念間の関連性を「リンク（エッジ）」とする巨大なネットワーク（意味ネットワーク）としてモデル化されます。

## 2. 基本的なメカニズム
活性化拡散モデルの基本的な動作原理は以下の通りです：

1. **ノードの活性化（シードの発火）:** 
   外部からの刺激（見聞きした言葉など）によって、ネットワーク内の特定のノードが活性化（発火）します。
2. **ネットワークを通じた拡散:** 
   活性化されたノードのエネルギーは、リンクを通じて隣接するノードへと拡散（伝播）していきます。
3. **リンク強度による重み付け:** 
   リンクには「強度（Weight）」や距離の概念があり、関連性が強いリンクほど多くのエネルギーが伝播します。逆に、関連性が薄いノードへはエネルギーがあまり伝播しません。
4. **しきい値と減衰（Decay）:** 
   伝播するごとに活性化のエネルギーは減衰率（Decay Factor）に従って小さくなります。エネルギーが特定のしきい値（Threshold）を下回ると、それ以上は拡散しません。これにより、無限にネットワーク全体が発火するのを防ぎます。

例えば、「消防車」という言葉を見聞きすると、「赤い」「火事」「サイレン」といった関連概念へのリンクを通じて連想が広がっていく現象をうまく説明できます。

## 3. AIシステムへの応用
近年、この認知モデルはAI、特に自然言語処理やナレッジグラフの分野で再評価されています。

### RAG（検索拡張生成）における活用課題の克服
単純なベクトル検索によるRAGでは、クエリと直接的な類似性を持つドキュメントしか検索できません。しかし、活性化拡散モデルを応用することで、**「Aに関連するB、Bに関連するC」といった多ホップ（Multi-hop）の推論や連想**が可能になります。

### ローカルメモリシステムでの実装例
ユーザーが作成したMarkdownノート（Obsidianなど）をノードとし、Wikilink（`[[リンク]]`）をエッジとするネットワークにこのモデルを適用します。
ユーザーが新しくノートを書いた際、それに直接関連するノートを発火点（シード）とし、そこから一定の減衰率を持ってリンクを辿ることで、直接検索には引っかからないが、文脈的に有益な周辺ノートを「AIの連想記憶」として動的に引き出すことが可能になります。

## 4. システム設計時のパラメータチューニング
システムとして実装する上で、以下のパラメータ設定が挙動に大きく影響します。
* **初期活性値 (Initial Activation):** シードとなるノード群に最初に与えるエネルギー量。
* **減衰率 (Decay Rate または Alpha):** 1ホップごとにエネルギーがどれくらい減少するか。0に近いほどすぐに拡散が止まり、1に近いほど遠くまでネットワークを探索します。
* **終了しきい値 (Threshold):** 計算を打ち切るための足切りライン。計算リソースの節約に不可欠です。
* **発火ルール (Activation Function):** 複数のリンクからエネルギーを同時に受け取った場合、それをどう合算するか（単純な線形和か、非線形関数を通すかなど）。
